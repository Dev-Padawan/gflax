{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pix2pix-flax-2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ds4o1h4WHz9U"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/pix2pix\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wifwThPoEj7e",
        "colab": {}
      },
      "source": [
        "# !pip install -U tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kn-k8kTXuAlv",
        "colab": {}
      },
      "source": [
        "_URL = 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('facades.tar.gz',\n",
        "                                      origin=_URL,\n",
        "                                      extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CbTEt448b4R",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 400\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aO9ZAGH5K3SY",
        "colab": {}
      },
      "source": [
        "def load(image_file):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "\n",
        "  w = tf.shape(image)[1]\n",
        "\n",
        "  w = w // 2\n",
        "  real_image = image[:, :w, :]\n",
        "  input_image = image[:, w:, :]\n",
        "\n",
        "  input_image = tf.cast(input_image, tf.float32)\n",
        "  real_image = tf.cast(real_image, tf.float32)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4OLHMpsQ5aOv",
        "colab": {}
      },
      "source": [
        "inp, re = load(PATH+'train/100.jpg')\n",
        "# casting to int for matplotlib to show the image\n",
        "plt.figure()\n",
        "plt.imshow(inp/255.0)\n",
        "plt.figure()\n",
        "plt.imshow(re/255.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rwwYQpu9FzDu",
        "colab": {}
      },
      "source": [
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yn3IwqhiIszt",
        "colab": {}
      },
      "source": [
        "def random_crop(input_image, real_image):\n",
        "  stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "  cropped_image = tf.image.random_crop(\n",
        "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "  return cropped_image[0], cropped_image[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "muhR2cgbLKWW",
        "colab": {}
      },
      "source": [
        "# normalizing the images to [-1, 1]\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVQOjcPVLrUc",
        "colab": {}
      },
      "source": [
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "  # resizing to 286 x 286 x 3\n",
        "  input_image, real_image = resize(input_image, real_image, 286, 286)\n",
        "\n",
        "  # randomly cropping to 256 x 256 x 3\n",
        "  input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # random mirroring\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n0OGdi6D92kM",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(4):\n",
        "  rj_inp, rj_re = random_jitter(inp, re)\n",
        "  plt.subplot(2, 2, i+1)\n",
        "  plt.imshow(rj_inp/255.0)\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyaP4hLJ8b4W",
        "colab": {}
      },
      "source": [
        "def load_image_train(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VB3Z6D_zKSru",
        "colab": {}
      },
      "source": [
        "def load_image_test(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = resize(input_image, real_image,\n",
        "                                   IMG_HEIGHT, IMG_WIDTH)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PIGN6ouoQxt3"
      },
      "source": [
        "## Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SQHmYSmk8b4b",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = tfds.as_numpy(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MS9J0yA58b4g",
        "colab": {}
      },
      "source": [
        "test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image_test)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = tfds.as_numpy(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Build the Generator\n",
        "  * The architecture of generator is a modified U-Net.\n",
        "  * Each block in the encoder is (Conv -> Batchnorm -> Leaky ReLU)\n",
        "  * Each block in the decoder is (Transposed Conv -> Batchnorm -> Dropout(applied to the first 3 blocks) -> ReLU)\n",
        "  * There are skip connections between the encoder and decoder (as in U-Net).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqqvWxlw8b4l",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4YZyYgqXOTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpVOMswxjKup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip uninstall flax\n",
        "! pip install git+https://github.com/google/flax.git#egg=flax\n",
        "import functools\n",
        "\n",
        "import jax\n",
        "import flax\n",
        "\n",
        "import numpy as onp\n",
        "import jax.numpy as jnp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3R09ATE_SH9P",
        "colab": {}
      },
      "source": [
        "class DownSample(flax.nn.Module):\n",
        "  def apply(self, x, features, size, apply_batchnorm=True):\n",
        "    # print(\"=====\", features, size)\n",
        "    x = flax.nn.Conv(x, features=features, kernel_size=(size, size), strides=(2, 2), padding='SAME', bias=False)\n",
        "    if apply_batchnorm:\n",
        "      x = flax.nn.BatchNorm(x)\n",
        "    x = flax.nn.leaky_relu(x)\n",
        "    return x\n",
        "\n",
        "class UpSample(flax.nn.Module):\n",
        "  def apply(self, x, features, size, apply_dropout=True):\n",
        "    x = flax.nn.ConvTranspose(x, features=features, kernel_size=(size, size), strides=(2, 2), padding='SAME', bias=False)\n",
        "    x = flax.nn.BatchNorm(x)\n",
        "    if apply_dropout:\n",
        "      x = flax.nn.dropout(x, 0.5)\n",
        "    x = flax.nn.relu(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uvhCAfVxg82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "down_list = [[64, 4, False],\n",
        "             [128, 4],\n",
        "             [256, 4],\n",
        "             [512, 4],\n",
        "             [512, 4],\n",
        "             [512, 4],\n",
        "             [512, 4],\n",
        "             [512, 4]]\n",
        "\n",
        "up_list = [[512, 4, True],\n",
        "           [512, 4, True],\n",
        "           [512, 4, True],\n",
        "           [512, 4],\n",
        "           [256, 4],\n",
        "           [128, 4],\n",
        "           [64, 4]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO656vFGjYKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(flax.nn.Module):\n",
        "  def apply(self, x):\n",
        "    skips = []\n",
        "    for down in down_list:\n",
        "      x = DownSample(x, *down)\n",
        "      # print('sss,', jnp.shape(x))\n",
        "      skips.append(x)\n",
        "    \n",
        "    skips = list(reversed(skips[:-1]))\n",
        "    # print(skips)\n",
        "    for up, skip in zip(up_list, skips):\n",
        "      x = UpSample(x, *up)\n",
        "      # tf.keras.layers.Concatenate()([x, skip])\n",
        "      # print('shpe = ', jnp.shape(x), jnp.shape(skip))\n",
        "      x = jnp.concatenate((x,skip))\n",
        "    \n",
        "    x = flax.nn.ConvTranspose(x, features=OUTPUT_CHANNELS, kernel_size=(4,4), strides=(2,2), padding='SAME')\n",
        "    x = flax.nn.tanh(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl0rCFEPoHth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LAMBDA = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BXkbWrYoaYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.vmap\n",
        "def binary_cross_entropy_loss(x, y):\n",
        "  max_val = jnp.clip(x, 0, None)\n",
        "  loss = x - x * y + max_val + jnp.log(np.exp(-max_val) + jnp.exp((-x - max_val)))\n",
        "  return loss.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZy3mcwO2YpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.vmap\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = binary_cross_entropy_loss(jnp.ones_like(disc_generated_output), disc_generated_output)\n",
        "  \n",
        "  l1_loss = jnp.mean(jnp.absolute(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  # think about negative\n",
        "  return total_gen_loss, gan_loss, l1_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxF_7eS73VL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(flax.nn.Module):\n",
        "  def apply(self, x):\n",
        "    x = DownSample(x, 64, 4, False)\n",
        "    x = DownSample(x, 128, 4)\n",
        "    x = DownSample(x, 256, 4)\n",
        "\n",
        "    x = jnp.pad(x, 1) # padding with zeros\n",
        "\n",
        "    x = flax.nn.Conv(x, 512, kernel_size=(4,4), strides=(1,1), bias=False)\n",
        "    x = flax.nn.BatchNorm(x)\n",
        "    x = flax.nn.leaky_relu(x)\n",
        "\n",
        "    x = jnp.pad(x, 1)\n",
        "\n",
        "    x = flax.nn.Conv(x, 1, kernel_size=(4,4), strides=(1,1))\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW4ceU1080yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.vmap\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = binary_cross_entropy_loss(jnp.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = binary_cross_entropy_loss(jnp.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "  \n",
        "  return total_disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EknA6VFe--_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "@functools.partial(jax.jit, static_argnums=(1, 2, 3))\n",
        "def create_model(key, batch_size, image_size, model_def):\n",
        "  input_shape = (batch_size, image_size, image_size, 3)\n",
        "  with flax.nn.stateful() as init_state:\n",
        "    with flax.nn.stochastic(jax.random.PRNGKey(0)):\n",
        "      _, initial_params = model_def.init_by_shape(key, [(input_shape, jnp.float32)])\n",
        "      model = flax.nn.Model(model_def, initial_params)\n",
        "  return model, init_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0rhEn6R70-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_optimizer(model, learning_rate, beta):\n",
        "  optimizer_def = flax.optim.Adam(learning_rate=learning_rate,\n",
        "                                 beta1=beta)\n",
        "  optimizer = optimizer_def.create(model)\n",
        "  optimizer = flax.jax_utils.replicate(optimizer)\n",
        "  return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mGz0pCxKSVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key = jax.random.PRNGKey(0)\n",
        "generator_model, generator_state = create_model(key, BATCH_SIZE, IMG_HEIGHT, Generator)\n",
        "discriminator_model, discriminator_state = create_model(key, BATCH_SIZE, IMG_HEIGHT, Discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKb-wLiy9b0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = create_optimizer(generator_model, 2e-4, 0.5)\n",
        "discriminator_optimizer = create_optimizer(discriminator_model, 2e-4, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIR9I74Sffec",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lVRtx47-Gdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input, tar):\n",
        "  # with flax.nn.stateful(state):\n",
        "  with flax.nn.stochastic(jax.random.PRNGKey(0)):\n",
        "    prediction = model(test_input)\n",
        "  # print(\"-----\")\n",
        "  plt.figure(figsize=(15,15))\n",
        "\n",
        "  display_list = [test_input[0], tar[0], prediction[0]]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvF5FwrIf61c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 0\n",
        "for example_input, example_target in test_dataset:\n",
        "  generate_images(generator_model, example_input, example_target)\n",
        "  j+=1\n",
        "  if j > 3:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s91E4yI1hXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.jit\n",
        "def train_step(generator_opt, discriminator_opt, input_image, target_image):\n",
        "  \"\"\"Perform a single training step.\"\"\"\n",
        "  def loss_fn(gen_model, disc_model):\n",
        "    \"\"\"loss function used for training.\"\"\"\n",
        "    # with flax.nn.stateful(state) as new_state:\n",
        "    with flax.nn.stochastic(jax.random.PRNGKey(0)):\n",
        "      gen_output = gen_model(input_image)\n",
        "      \n",
        "      disc_real_output = disc_model(jnp.concatenate((input_image, target_image)))\n",
        "      disc_generated_output = disc_model(jnp.concatenate((input_image, gen_output)))\n",
        "    \n",
        "    gen_total_loss, _, _ = generator_loss(disc_generated_output, gen_output, target_image)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "    \n",
        "    return gen_total_loss, disc_loss\n",
        "\n",
        "  step = generator_opt.state.step\n",
        "  gen_grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  disc_grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  _, gen_grad = gen_grad_fn(generator_opt.target, discriminator_opt.target)\n",
        "  (gen_total_loss, disc_loss), disc_grad = disc_grad_fn(generator_opt.target, discriminator_opt.target)\n",
        "\n",
        "  new_gen_opt = generator_opt.apply_gradient(gen_grad)\n",
        "  new_disc_opt = discriminator_opt.apply_gradient(disc_grad)\n",
        "  # metrics = compute_metrics(logits, batch['label'])\n",
        "  # metrics['learning_rate'] = lr\n",
        "  return new_gen_opt, new_disc_opt, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnqDze70kml8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_train_step = jax.pmap(functools.partial(train_step), axis_name='batch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98XIvG8Hi05o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  start = time.time()\n",
        "\n",
        "  display.clear_output(wait=True)\n",
        "  j=0\n",
        "  for example_input, example_target in test_dataset:\n",
        "    generate_images(generator_model, example_input, example_target)\n",
        "    j+=1\n",
        "    if j > 1:\n",
        "      break\n",
        "  print(\"Epoch: \", epoch)\n",
        "\n",
        "  # Train\n",
        "  \n",
        "  for n, (input_image, target_image) in enumerate(test_dataset):\n",
        "    print('.', end='')\n",
        "    if n+1 % 100 == 0:\n",
        "      print()\n",
        "    p_train_step(generator_optimizer, discriminator_optimizer, input_image, target_image)\n",
        "  print()\n",
        "\n",
        "  # saving (checkpoint) the model every 20 epochs\n",
        "  # if (epoch + 1) % 20 == 0:\n",
        "  #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "USKeeUTaxHha",
        "colab": {}
      },
      "source": [
        "for example_input, example_target in test_dataset:\n",
        "  # generate_images(generator, example_input, example_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P1EGz25jiue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top():\n",
        "  a = 3\n",
        "  def k():\n",
        "    a +=5\n",
        "  print(a)\n",
        "  k()\n",
        "  print(a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6clohq92zgz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MWGp1vLzhiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    Example:\n",
        "      input_shape = (batch_size, image_size, image_size, 3)\n",
        "      model_output, initial_params = model.init_by_shape(jax.random.PRNGKey(0),\n",
        "                                                         input_specs=[(input_shape, jnp.float32)])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}