{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9WN5UZzRqkE"
   },
   "source": [
    "# Dropout in image classification\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/flax/blob/main/docs/tutorials/dropout_tutorial.ipynb)\n",
    "\n",
    "This tutorial provides an end-to-end example of a simple image classification model with a dropout layer in Flax. The [dropout](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf) stochastic regularization technique randomly removes hidden and visible units in a network. The randomness in Flax's [`Dropout`](https://flax.readthedocs.io/en/latest/api_reference/_autosummary/flax.linen.Dropout.html#flax.linen.Dropout) layer is handled internally with [`flax.linen.Module.make_rng`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen.html#flax.linen.Module.make_rng). This is covered in more detail in [ðŸ”ª Flax - The Sharp Bits ðŸ”ª `flax.linen.Dropout` layer and randomness](https://flax.readthedocs.io/en/latest/notebooks/flax_sharp_bits.html#flax-linen-dropout-layer-and-randomness).\n",
    "\n",
    "The example below uses a lot of fundamental concepts covered in [Getting started](https://flax.readthedocs.io/en/latest/getting_started.html). If you're new to Flax, start there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpnTy21qSWYV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "- Install/upgrade Flax, which will also set up [Optax](https://optax.readthedocs.io/) (for common optimizers and loss functions), and JAX.\n",
    "- Install [TensorFlow Datasets](https://www.tensorflow.org/datasets) to load a dataset for this tutorial.\n",
    "- Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Q1sL4cQTbAt"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q flax tensorflow_datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kYKJYxxXUiL"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "\n",
    "from flax import linen as nn           # The Flax Linen API\n",
    "from flax.training import train_state  # A Flax dataclass to keep the train state\n",
    "\n",
    "import numpy as np                     # Ordinary NumPy\n",
    "import optax                           # The Optax library\n",
    "import tensorflow_datasets as tfds     # TFDS for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTf7YtdgWWNY"
   },
   "source": [
    "Use a JAX PRNG key and split it to get one key for parameter initialization, and another one for dropout randomness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9lWcsK1WUzL"
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "root_key = jax.random.PRNGKey(seed=seed)\n",
    "main_key, params_key, dropout_key = jax.random.split(key=root_key, num=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9pSTAIOSU1X"
   },
   "source": [
    "Create a simple Flax model, subclassed from [Flax `Module`](https://flax.readthedocs.io/en/latest/guides/flax_basics.html#module-basics). Note that:\n",
    "\n",
    "- To add a dropout layer in Flax, use [`flax.linen.Dropout`](https://flax.readthedocs.io/en/latest/api_reference/_autosummary/flax.linen.Dropout.html#flax.linen.Dropout).\n",
    "- In `flax.linen.Dropout`, the `deterministic` argument is `None` by default. If `false`, the inputs are scaled by `1 / (1 - dropout_rate)` and masked. When it's `true`, no mask is applied (the dropout is turned off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNWL1sDOZpTj"
   },
   "outputs": [],
   "source": [
    "# A simple convolutional network with a dropout layer.\n",
    "class CNN(nn.Module):\n",
    "  training: bool\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = x.reshape((x.shape[0], -1))  # Flatten\n",
    "    # Set the dropout layer with a rate of 50% .\n",
    "    # When the `deterministic` flag is `True`, dropout is turned off.\n",
    "    x = nn.Dropout(rate=0.5, deterministic=not self.training)(x)\n",
    "    x = nn.Dense(features=10)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk-E94kkT51x"
   },
   "source": [
    "Define the loss function using [Optax](https://optax.readthedocs.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXUHeCptgRXF"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "  labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDOYyP4uT-Wt"
   },
   "source": [
    "Create a function for the loss and accuracy metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IkOdtakLok5"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(*, logits, labels):\n",
    "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "  }\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pL8F_kN5UAg1"
   },
   "source": [
    "Write a function for loading your dataset with [TensorFlow Datasets](https://www.tensorflow.org/datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9sGGsSzLx13"
   },
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "  ds_builder = tfds.builder('mnist')\n",
    "  ds_builder.download_and_prepare()\n",
    "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "  return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEiC2gBXUHlS"
   },
   "source": [
    "Create another function for creating the Flax [`TrainState`](https://flax.readthedocs.io/en/latest/api_reference/flax.training.html#train-state) with an [Optax](https://optax.readthedocs.io/) optimizer. Remember that:\n",
    "\n",
    "- When initializing the variables, use the `params_key` PRNG key (the `params_key` is equivalent to a dictionary of PRNGs).\n",
    "- The model constructor is `training=False` before you start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aae3rz125R6z"
   },
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate):\n",
    "  # Instantiate the model with `training=False`.\n",
    "  cnn = CNN(training=False)\n",
    "  # Initialize the `params`. Use the `params_key` PRNG key.\n",
    "  # (Here, you are providing only one PRNG key.) \n",
    "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "  # Use the Adam optimizer with a learning rate.\n",
    "  tx = optax.adam(learning_rate)\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRDfpGlkV5m5"
   },
   "source": [
    "Define the training step function. Note that:\n",
    "\n",
    "- During the forward pass with [`flax.linen.apply()`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen.html#init-apply), use the `'dropout'` key (`dropout_key`) for the `rngs` argument.\n",
    "- The model constructor argument should be set to `training=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPsXnjKVH0hV"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    # Perform the forward pass with `flax.linen.apply()`.\n",
    "    # Use the `dropout_key` for the `rngs` argument.\n",
    "    logits = CNN(training=True).apply({'params': params}, batch['image'], rngs={'dropout': dropout_key})\n",
    "    # Calculatet the loss,\n",
    "    loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "    return loss, logits\n",
    "  # Compute the gradients\n",
    "  grad_fn = jax.grad(loss_fn, has_aux=True)\n",
    "  grads, logits = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "  return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN5u62E6V8kJ"
   },
   "source": [
    "Write the evaluation step function. Remember to set the model constructor argument to `training=false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKODKHNNH_1k"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "  logits = CNN(training=False).apply({'params': params}, batch['image'])\n",
    "  return compute_metrics(logits=logits, labels=batch['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dio74TEWBjt"
   },
   "source": [
    "Create a function for training the model for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dY_lKUz5SuG"
   },
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "  train_ds_size = len(train_ds['image'])\n",
    "  steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "  perms = jax.random.permutation(rng, train_ds_size)\n",
    "  perms = perms[:steps_per_epoch * batch_size]  # Skip an incomplete batch.\n",
    "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "  batch_metrics = []\n",
    "  for perm in perms:\n",
    "    batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "    state, metrics = train_step(state, batch)\n",
    "    batch_metrics.append(metrics)\n",
    "\n",
    "  # Compute the mean of metrics across each batch in an epoch.\n",
    "  batch_metrics_np = jax.device_get(batch_metrics)\n",
    "  epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]}\n",
    "\n",
    "  print('Train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
    "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
    "\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuX4Ewz3hMZM"
   },
   "source": [
    "Create a model evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sq5z385KPTuu"
   },
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "  metrics = eval_step(params, test_ds)\n",
    "  metrics = jax.device_get(metrics)\n",
    "  summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "  return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-Ij6G7jw8xc"
   },
   "source": [
    "Download the dataset and split it into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5JcAhIs5Szz"
   },
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDfng16c5S31"
   },
   "source": [
    "Initialize the Flax `TrainState`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrLNat6c5S7Z"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "state = create_train_state(rng=params_key, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b66WaNi8xBHz"
   },
   "source": [
    "Train the model over 10 epochs, and evaluate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpSx0ZBV5S-o"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  # Use a separate PRNG key to permute image data during shuffling.\n",
    "  main_key, input_rng = jax.random.split(key=root_key)\n",
    "  # Run an optimization step over a training batch.\n",
    "  state = train_epoch(state=state,\n",
    "                      train_ds=train_ds,\n",
    "                      batch_size=batch_size,\n",
    "                      epoch=epoch,\n",
    "                      rng=input_rng)\n",
    "  # Evaluate on the test set after each training epoch.\n",
    "  test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "  print('  Test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "      epoch, test_loss, test_accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dropout_tutorial.ipynb",
   "toc_visible": true
  },
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
